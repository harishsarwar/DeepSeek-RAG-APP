# PDF-Based QA Chatbot with DeepSeeek


This project enables users to ask **context-aware** questions based on a **PDF document** using **FAISS vector search** and **LangChain with Ollama LLM**.

## ğŸš€ Features
âœ… **PDF Ingestion** â€“ Extracts text and splits it into meaningful chunks  
âœ… **FAISS Vector Store** â€“ Stores embeddings for fast retrieval  
âœ… **Contextual Q&A** â€“ Provides answers based on document content  
âœ… **Streamlit UI** â€“ Interactive chatbot interface  
âœ… **Ollama LLM Integration** â€“ Uses local LLM for response generation  

## ğŸ”¥ Use Cases
ğŸ”¹ **Resume-Based Q&A** â€“ Ask questions about a resume document  
ğŸ”¹ **Legal Document Search** â€“ Retrieve relevant legal clauses  
ğŸ”¹ **Research Paper Assistant** â€“ Extract insights from academic PDFs  
ğŸ”¹ **Medical Report Analysis** â€“ Answer queries based on medical documents  

ğŸ”¹ **And show on according to the PDf**

## ğŸ“ Project Structure
ğŸ“‚ project-folder
 â”œâ”€â”€ main.py                # Streamlit chatbot UI
 â”œâ”€â”€ data_ingestion.py       # PDF processing & FAISS database creation
 â”œâ”€â”€ vectorstore/            # FAISS vector storage
 â”œâ”€â”€ Resume (5).pdf          # Sample PDF file
 â”œâ”€â”€ .env                    # API keys (not included in repo)
 â”œâ”€â”€ requirements.txt        # Dependencies
 â”œâ”€â”€ README.md               # Project documentation


## â— Troubleshooting
If FAISS does not load data in main.py, rerun data_ingestion.py
Ensure Ollama is running at http://localhost:11434
Check if .env is correctly set





